{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a5260a-102b-40e7-962b-97a5d4b5999a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T16:30:35.367016Z",
     "iopub.status.busy": "2024-07-12T16:30:35.366635Z",
     "iopub.status.idle": "2024-07-12T16:30:35.373841Z",
     "shell.execute_reply": "2024-07-12T16:30:35.373031Z",
     "shell.execute_reply.started": "2024-07-12T16:30:35.366980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f685fe94-118f-454b-a6ca-8554322f054b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T16:30:48.509626Z",
     "iopub.status.busy": "2024-07-12T16:30:48.509251Z",
     "iopub.status.idle": "2024-07-12T16:30:49.815937Z",
     "shell.execute_reply": "2024-07-12T16:30:49.815060Z",
     "shell.execute_reply.started": "2024-07-12T16:30:48.509600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-12 16:30:49--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-12 16:30:49 (54.3 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54228a39-99cc-4c31-86f1-333567711f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T16:34:46.594758Z",
     "iopub.status.busy": "2024-07-12T16:34:46.594271Z",
     "iopub.status.idle": "2024-07-12T16:34:50.446169Z",
     "shell.execute_reply": "2024-07-12T16:34:50.445481Z",
     "shell.execute_reply.started": "2024-07-12T16:34:46.594730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d196775d-6293-4dc1-bb9c-d82ff23aac3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T16:36:04.763730Z",
     "iopub.status.busy": "2024-07-12T16:36:04.763235Z",
     "iopub.status.idle": "2024-07-12T16:36:04.772654Z",
     "shell.execute_reply": "2024-07-12T16:36:04.772021Z",
     "shell.execute_reply.started": "2024-07-12T16:36:04.763700Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7ab390ecd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the random seed to 0 so that the results are reproducible\n",
    "torch.random.manual_seed(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709c64c-ad43-4cee-8a23-fd1bbdcca022",
   "metadata": {},
   "source": [
    "# Testing Phi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59977897-e4f9-4467-9078-dc4445a12efd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T16:36:33.528321Z",
     "iopub.status.busy": "2024-07-12T16:36:33.527926Z",
     "iopub.status.idle": "2024-07-12T16:37:19.770006Z",
     "shell.execute_reply": "2024-07-12T16:37:19.769227Z",
     "shell.execute_reply.started": "2024-07-12T16:36:33.528293Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34523bfcb4fb42798cc64143021bdea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43482fb3c81f44cbae05c73507a045b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c96a606b6648f6a5db0ea5ae268385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98133334c8f448768718a79ed9d360e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d23605c2c434702a0f995ae6f3a98ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4a8d9e1a82475c8bd109ba7a42f1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f929e2e106436ab4b5d0eec54bf4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d979cbd3ac2d4d35b09a7c8b81badf58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38228e5eef9c47dea905172a0bf609b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc2409ffa224e32b9ed9edc54e21ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9f28a756fc45faa9840c847d8182fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12258d0954f640fbba1a565202a343ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb83b0293e64a46bcf8a53e2626c070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa41908874514b768837caf680c7c67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained( \n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",  \n",
    "    device_map=\"cuda\",  \n",
    "    torch_dtype=\"auto\",  \n",
    "    trust_remote_code=True,  \n",
    ") \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df7d6182-b1bd-4552-a963-844d2951c2af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T16:38:40.705118Z",
     "iopub.status.busy": "2024-07-12T16:38:40.704728Z",
     "iopub.status.idle": "2024-07-12T16:38:40.708899Z",
     "shell.execute_reply": "2024-07-12T16:38:40.708213Z",
     "shell.execute_reply.started": "2024-07-12T16:38:40.705091Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline to combine tokenizer and generator\n",
    "pipe = pipeline( \n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f5b871-30aa-4081-b08a-890bc78e3a9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T17:07:26.903424Z",
     "iopub.status.busy": "2024-07-12T17:07:26.903028Z",
     "iopub.status.idle": "2024-07-12T17:07:31.022320Z",
     "shell.execute_reply": "2024-07-12T17:07:31.021523Z",
     "shell.execute_reply.started": "2024-07-12T17:07:26.903395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry, but it seems you've missed the opportunity to join the course. However, I can help you find similar courses or provide information on how to enroll in future sessions. Would you like me to assist you with that?\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"I just discovered the course. Can I still join?\"}\n",
    "] \n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"return_full_text\": False, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "output = pipe(messages, **generation_args) \n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b0e99-0248-42ec-9830-bd6f86f5f35a",
   "metadata": {},
   "source": [
    "# Updating the RAG Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae015d8f-c336-484a-b3d2-220833c8b1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T17:08:40.001029Z",
     "iopub.status.busy": "2024-07-12T17:08:40.000502Z",
     "iopub.status.idle": "2024-07-12T17:08:40.569210Z",
     "shell.execute_reply": "2024-07-12T17:08:40.568468Z",
     "shell.execute_reply.started": "2024-07-12T17:08:40.000999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f79ec1cebe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9428fa6e-4e1c-42f1-bdc5-31cce22b28ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T17:08:53.577513Z",
     "iopub.status.busy": "2024-07-12T17:08:53.577087Z",
     "iopub.status.idle": "2024-07-12T17:08:53.581731Z",
     "shell.execute_reply": "2024-07-12T17:08:53.580969Z",
     "shell.execute_reply.started": "2024-07-12T17:08:53.577486Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "828cc7f8-4f55-4647-9c19-41620e4080c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T17:09:40.825840Z",
     "iopub.status.busy": "2024-07-12T17:09:40.825471Z",
     "iopub.status.idle": "2024-07-12T17:09:40.831922Z",
     "shell.execute_reply": "2024-07-12T17:09:40.831100Z",
     "shell.execute_reply.started": "2024-07-12T17:09:40.825812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    messages = [ \n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "    ] \n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 500, \n",
    "        \"return_full_text\": False, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    output = pipe(messages, **generation_args) \n",
    "    result = output[0]['generated_text']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e4b910-bd64-41f5-9dd5-b9cfc6ece197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T17:09:52.824726Z",
     "iopub.status.busy": "2024-07-12T17:09:52.824342Z",
     "iopub.status.idle": "2024-07-12T17:09:52.828837Z",
     "shell.execute_reply": "2024-07-12T17:09:52.827982Z",
     "shell.execute_reply.started": "2024-07-12T17:09:52.824701Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c30ed4-6f59-4474-aa49-10969a3eb556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T17:10:00.271844Z",
     "iopub.status.busy": "2024-07-12T17:10:00.271473Z",
     "iopub.status.idle": "2024-07-12T17:10:04.321404Z",
     "shell.execute_reply": "2024-07-12T17:10:04.320703Z",
     "shell.execute_reply.started": "2024-07-12T17:10:00.271816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, you can still join the course even if you discover it after the start date. You are still eligible to submit the homeworks, but remember to meet the deadlines for the final projects.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"I just discovered the course. Can I still join it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8ed02-3678-4a36-ad70-f92ea58c123d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
